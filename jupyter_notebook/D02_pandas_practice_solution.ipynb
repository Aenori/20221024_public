{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ce445c",
   "metadata": {},
   "source": [
    "Copyright (c) 2021 Stefanie Molin  \n",
    "MIT License  \n",
    "git@github.com:stefmolin/pandas-workshop.git  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a499f-fa07-4ca0-8ddd-c50e76eb0599",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Workbook\n",
    "\n",
    "Use this notebook to complete the exercises throughout the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d955d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "# Please execute this at the start of the notebook\n",
    "\n",
    "base_url = 'https://raw.githubusercontent.com/Aenori/20221024_public/main/help_files/pandas/'\n",
    "helper_files = ['2019_Yellow_Taxi_Trip_Data.csv', 'Meteorite_Landings.csv', 'tsa_melted_holiday_travel.csv']\n",
    "\n",
    "for helper_file in helper_files:\n",
    "    urllib.request.urlretrieve(base_url + helper_file, helper_file)\n",
    "\n",
    "taxi_file, meteorite_file, holiday_file = helper_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3a4b7",
   "metadata": {},
   "source": [
    "### Section 1\n",
    "\n",
    "#### Exercise 1.1\n",
    "##### Create a DataFrame by reading in the `2019_Yellow_Taxi_Trip_Data.csv` file. Examine the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa449dc1-4c0b-47ce-bba7-061568590d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_taxi = pd.read_csv(taxi_file)\n",
    "\n",
    "df_taxi.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8999f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vendorid', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'ratecodeid', 'store_and_fwd_flag',\n",
       "       'pulocationid', 'dolocationid', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52808c-cb6b-4a2b-a183-5c886bbe6b85",
   "metadata": {},
   "source": [
    "#### Exercise 1.2\n",
    "##### Find the dimensions (number of rows and number of columns) in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4e7275f-4009-4cc9-911d-da92efb79fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 18)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e9aa37-a244-4e4c-8caa-9d13ca8c7f71",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exercise 1.3\n",
    "##### Using the data in the `2019_Yellow_Taxi_Trip_Data.csv` file, calculate summary statistics for the `fare_amount`, `tip_amount`, `tolls_amount`, and `total_amount` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577fc58-fd5f-412b-aa2e-50c541c5778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_taxi.columns)\n",
    "df_taxi[['fare_amount', 'tip_amount', 'tolls_amount', 'total_amount']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf547b-a273-4327-b17a-2c10a58b96bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exercise 1.4\n",
    "##### Isolate the `fare_amount`, `tip_amount`, `tolls_amount`, and `total_amount` for the longest trip by distance (`trip_distance`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc75ecfc-19b5-438b-b078-eaf7cfc3e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the \\ at the end of the line means the line is continuing on next line\n",
    "df_taxi[['fare_amount', 'tip_amount', 'tolls_amount', 'total_amount']]\\\n",
    "        [df_taxi['trip_distance'] > df_taxi['trip_distance'].max() - 1e-6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d919d1",
   "metadata": {},
   "source": [
    "#### Exercise 1.5\n",
    "##### What is the vendorId that makes the most tip (column `tip_amount`) in average ? In total ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a378e20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48c03afb",
   "metadata": {},
   "source": [
    "#### Exercise 1.6\n",
    "##### What is the average distance (`trip_distance`) of the first half of the data_frame ? Of the second half ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb076d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9aaeed4-127a-412b-93f6-b179e4ba85f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Section 2\n",
    "\n",
    "#### Exercise 2.1\n",
    "##### Read in the meteorite data from the `Meteorite_Landings.csv` file, rename the `mass (g)` column to `mass`, and drop all the latitude and longitude columns. Sort the result by mass in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ada49a08-cda7-42ee-ade9-8bb2a2c5a9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass</th>\n",
       "      <th>fall</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16392</th>\n",
       "      <td>Hoba</td>\n",
       "      <td>11890</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron, IVB</td>\n",
       "      <td>60000000.0</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1920 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>Cape York</td>\n",
       "      <td>5262</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron, IIIAB</td>\n",
       "      <td>58200000.0</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1818 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>Campo del Cielo</td>\n",
       "      <td>5247</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron, IAB-MG</td>\n",
       "      <td>50000000.0</td>\n",
       "      <td>Found</td>\n",
       "      <td>12/22/1575 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370</th>\n",
       "      <td>Canyon Diablo</td>\n",
       "      <td>5257</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron, IAB-MG</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1891 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>Armanty</td>\n",
       "      <td>2335</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron, IIIE</td>\n",
       "      <td>28000000.0</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1898 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38282</th>\n",
       "      <td>Wei-hui-fu (a)</td>\n",
       "      <td>24231</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1931 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38283</th>\n",
       "      <td>Wei-hui-fu (b)</td>\n",
       "      <td>24232</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1931 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38285</th>\n",
       "      <td>Weiyuan</td>\n",
       "      <td>24233</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Mesosiderite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1978 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41472</th>\n",
       "      <td>Yamato 792768</td>\n",
       "      <td>28117</td>\n",
       "      <td>Valid</td>\n",
       "      <td>CM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1979 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45698</th>\n",
       "      <td>Zapata County</td>\n",
       "      <td>30393</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Iron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>01/01/1930 12:00:00 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45716 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name     id nametype      recclass        mass   fall  \\\n",
       "16392             Hoba  11890    Valid     Iron, IVB  60000000.0  Found   \n",
       "5373         Cape York   5262    Valid   Iron, IIIAB  58200000.0  Found   \n",
       "5365   Campo del Cielo   5247    Valid  Iron, IAB-MG  50000000.0  Found   \n",
       "5370     Canyon Diablo   5257    Valid  Iron, IAB-MG  30000000.0  Found   \n",
       "3455           Armanty   2335    Valid    Iron, IIIE  28000000.0  Found   \n",
       "...                ...    ...      ...           ...         ...    ...   \n",
       "38282   Wei-hui-fu (a)  24231    Valid          Iron         NaN  Found   \n",
       "38283   Wei-hui-fu (b)  24232    Valid          Iron         NaN  Found   \n",
       "38285          Weiyuan  24233    Valid  Mesosiderite         NaN  Found   \n",
       "41472    Yamato 792768  28117    Valid           CM2         NaN  Found   \n",
       "45698    Zapata County  30393    Valid          Iron         NaN  Found   \n",
       "\n",
       "                         year  \n",
       "16392  01/01/1920 12:00:00 AM  \n",
       "5373   01/01/1818 12:00:00 AM  \n",
       "5365   12/22/1575 12:00:00 AM  \n",
       "5370   01/01/1891 12:00:00 AM  \n",
       "3455   01/01/1898 12:00:00 AM  \n",
       "...                       ...  \n",
       "38282  01/01/1931 12:00:00 AM  \n",
       "38283  01/01/1931 12:00:00 AM  \n",
       "38285  01/01/1978 12:00:00 AM  \n",
       "41472  01/01/1979 12:00:00 AM  \n",
       "45698  01/01/1930 12:00:00 AM  \n",
       "\n",
       "[45716 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meteorite = pd.read_csv(meteorite_file)\n",
    "\n",
    "other_df = df_meteorite.rename(columns={'mass (g)' : 'mass'})\\\n",
    "                       .drop(columns=['reclat', 'reclong', 'GeoLocation'])\\\n",
    "                       .sort_values(['mass'], ascending=False)  \n",
    "\n",
    "other_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994b42d-8205-4584-84a0-b3a7fa56c9b1",
   "metadata": {},
   "source": [
    "#### Exercise 2.2\n",
    "##### Using the meteorite data from the `Meteorite_Landings.csv` file, update the `year` column to only contain the year, convert it to a numeric data type, and create a new column indicating whether the meteorite was observed falling before 1970. Set the index to the `id` column and extract all the rows with IDs between 10,036 and 10,040 (inclusive) with `loc[]`.\n",
    "\n",
    "###### **Hint 1**: Use `year.str.slice()` to grab a substring.\n",
    "\n",
    "###### **Hint 2**: Make sure to sort the index before using `loc[]` to select the range.\n",
    "\n",
    "###### **Bonus**: There's a data entry error in the `year` column. Can you find it? (Don't spend too much time on this.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02605233-73c5-4cd9-8134-b38ab749e8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45716, 10)\n",
      "45425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 860.,  920., 1399., 1490., 1491., 1495., 1519., 1575., 1583.,\n",
       "       1600., 1621., 1623., 1628., 1632., 1636., 1637., 1647., 1654.,\n",
       "       1662., 1668., 1671., 1688., 1704., 1715., 1716., 1723., 1724.,\n",
       "       1740., 1741., 1749., 1750., 1751., 1753., 1766., 1768., 1769.,\n",
       "       1773., 1775., 1776., 1779., 1781., 1784., 1785., 1787., 1790.,\n",
       "       1791., 1792., 1793., 1794., 1795., 1796., 1797., 1798., 1801.,\n",
       "       1803., 1804., 1805., 1806., 1807., 1808., 1809., 1810., 1811.,\n",
       "       1812., 1813., 1814., 1815., 1817., 1818., 1819., 1820., 1821.,\n",
       "       1822., 1823., 1824., 1825., 1826., 1827., 1828., 1829., 1830.,\n",
       "       1831., 1832., 1833., 1834., 1835., 1836., 1837., 1838., 1839.,\n",
       "       1840., 1841., 1842., 1843., 1844., 1845., 1846., 1847., 1848.,\n",
       "       1849., 1850., 1851., 1852., 1853., 1854., 1855., 1856., 1857.,\n",
       "       1858., 1859., 1860., 1861., 1862., 1863., 1864., 1865., 1866.,\n",
       "       1867., 1868., 1869., 1870., 1871., 1872., 1873., 1874., 1875.,\n",
       "       1876., 1877., 1878., 1879., 1880., 1881., 1882., 1883., 1884.,\n",
       "       1885., 1886., 1887., 1888., 1889., 1890., 1891., 1892., 1893.,\n",
       "       1894., 1895., 1896., 1897., 1898., 1899., 1900., 1901., 1902.,\n",
       "       1903., 1904., 1905., 1906., 1907., 1908., 1909., 1910., 1911.,\n",
       "       1912., 1913., 1914., 1915., 1916., 1917., 1918., 1919., 1920.,\n",
       "       1921., 1922., 1923., 1924., 1925., 1926., 1927., 1928., 1929.,\n",
       "       1930., 1931., 1932., 1933., 1934., 1935., 1936., 1937., 1938.,\n",
       "       1939., 1940., 1941., 1942., 1943., 1944., 1945., 1946., 1947.,\n",
       "       1948., 1949., 1950., 1951., 1952., 1953., 1954., 1955., 1956.,\n",
       "       1957., 1958., 1959., 1960., 1961., 1962., 1963., 1964., 1965.,\n",
       "       1966., 1967., 1968., 1969., 1970., 1971., 1972., 1973., 1974.,\n",
       "       1975., 1976., 1977., 1978., 1979., 1980., 1981., 1982., 1983.,\n",
       "       1984., 1985., 1986., 1987., 1988., 1989., 1990., 1991., 1992.,\n",
       "       1993., 1994., 1995., 1996., 1997., 1998., 1999., 2000., 2001.,\n",
       "       2002., 2003., 2004., 2005., 2006., 2007., 2008., 2009., 2010.,\n",
       "       2011., 2012., 2013., 2101.,   nan])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "df_meteorite = pd.read_csv(meteorite_file)\n",
    "print(df_meteorite.shape)\n",
    "print(df_meteorite['year'].count())\n",
    "\n",
    "def year_to_string(s):\n",
    "    try:\n",
    "        return dt.datetime.strptime(s, '%m/%d/%Y %H:%M:%S %p').year\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "year_values = df_meteorite['year'].apply(year_to_string).unique()\n",
    "year_values.sort()\n",
    "year_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1f8ab-ad56-412d-8df7-a59252f282cf",
   "metadata": {},
   "source": [
    "#### Exercise 2.3\n",
    "##### Using the meteorite data from the `Meteorite_Landings.csv` file, create a pivot table that shows both the number of meteorites and the 95th percentile of meteorite mass for those that were found versus observed falling per year from 2005 through 2009 (inclusive). Hint: Be sure to convert the `year` column to a number as we did in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511433c4-5a9d-41a4-8050-0e953225da0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4243c25b-6b5d-4fec-a818-3766be46c7a1",
   "metadata": {},
   "source": [
    "#### Exercise 2.4\n",
    "##### Using the meteorite data from the `Meteorite_Landings.csv` file, compare summary statistics of the mass column for the meteorites that were found versus observed falling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aebbf8-1935-449f-94d8-aea0e1b67b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fb76130-c968-4d24-bf11-3337f846a621",
   "metadata": {},
   "source": [
    "#### Exercise 2.5\n",
    "##### Using the taxi trip data in the `2019_Yellow_Taxi_Trip_Data.csv` file, resample the data to an hourly frequency based on the dropoff time. Calculate the total `trip_distance`, `fare_amount`, `tolls_amount`, and `tip_amount`, then find the 5 hours with the most tips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5423f5-c685-4bb2-ac01-8d334d26f341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b878c7da-bd82-4e95-9302-e68d67b56f31",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### Section 3\n",
    "\n",
    "#### Exercise 3.1\n",
    "##### Using the TSA traveler throughput data in the `tsa_melted_holiday_travel.csv` file, create box plots for traveler throughput for each year in the data. Hint: Pass `kind='box'` into the `plot()` method to generate box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d275b26-c701-4c32-b480-8a4b0119f830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bdaffc7-b865-41cd-bd6a-fb02576ce814",
   "metadata": {},
   "source": [
    "#### Exercise 3.2\n",
    "##### Using the TSA traveler throughput data in the `tsa_melted_holiday_travel.csv` file, create a heatmap that shows the 2019 TSA median traveler throughput by day of week and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe6aa8-9078-4dd8-98bb-7f68976f97a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81436a29-c7ca-40a3-b1c5-7a1947709bd3",
   "metadata": {},
   "source": [
    "#### Exercise 3.3\n",
    "##### Annotate the medians in the box plot from *[Exercise 3.1](#Exercise-3.1)*. Hint: The `x` coordinates will be 1, 2, and 3 for 2019, 2020, and 2021, respectively. Alternatively, to avoid hardcoding values, you can use the `Axes.get_xticklabels()` method, in which case you should look at the [documentation](https://matplotlib.org/stable/api/text_api.html) for the `Text` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d32c60-fd9f-4b35-a6ec-de1489951e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
